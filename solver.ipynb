{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigensolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme\n",
    "\n",
    "Do not submit this Jupyter Notebook. Please rewrite your code in a standalone\n",
    "python script for submission. Use this notebook as a code template only.\n",
    "\n",
    "Run this notebook in a virtual environment.\n",
    "\n",
    "Create a virtual environment:\n",
    "```bash\n",
    "python -m venv env\n",
    "```\n",
    "\n",
    "Use the virtual environment:\n",
    "```bash\n",
    ". env/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy qiskit qiskit-aer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [Pytorch website](https://pytorch.org/get-started/locally/) for installation options if you want to use GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit\n",
    "from qiskit_aer import AerSimulator\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum circuits\n",
    "\n",
    "In this section we will implement functions to build the quantum circuits needed\n",
    "for VQSE algorithm. Actually, the only circuit we need to implement is the\n",
    "ansatz $V(\\theta)$. See Figure 3 in [the\n",
    "paper](https://arxiv.org/abs/2004.01372) for a diagram of $V(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the two-qubit gate $B_\\mu(\\theta_\\mu)$\n",
    "\n",
    "Let's implement the two-qubit gate illustrated in Figure 3 (b) (top). This gate\n",
    "is defined by 4 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(theta1: float, theta2: float, theta3: float, theta4: float) -> QuantumCircuit:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement one layer\n",
    "\n",
    "Let's implement one layer of $V(\\theta)$. See Figure 3 (a) for a diagram. Note\n",
    "that the jagged pieces are one block wrapped around the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(num_qubits: int, thetas: NDArray[np.float64]) -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    num_qubits: int\n",
    "\n",
    "    thetas: A list of parameters. Each block uses four parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement $V(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(num_layers: int, num_qubits: int, thetas: NDArray[np.float64]) -> QuantumCircuit:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    num_qubits: int\n",
    "\n",
    "    thetas: A list of parameters. Each block uses four parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "Let's implement the cost function $C(\\theta)$, which measures the \"distance\"\n",
    "between the columns of $V(\\theta)$ and the eigenvectors of $AA^\\dagger$. The\n",
    "definition is\n",
    "\n",
    "$$ C(\\theta) = \\mathrm{Tr}(H V(\\theta) A A^\\dagger V(\\theta)^\\dagger) $$\n",
    "\n",
    "We can rewrite this as\n",
    "\n",
    "$$ C(\\theta) = \\sum_i \\sum_j |\\alpha_{ij}|^2 E_j $$\n",
    "\n",
    "(See p.5 in the lecture notes for proof). $\\alpha_{ij}$ is the $j$ th element of\n",
    "the vector $V(\\theta) |A_i\\rangle$, which is $V(\\theta)$ applied to the $i$ th\n",
    "column of $A$. $E_j$ is the $j$ th eigenvalue of the global Hamiltonian (see\n",
    "lecture notes). The Hamiltonian is supposed to be a square diagonal matrix, but\n",
    "we're only interested in the diagonal, so $E$ is just a vector. The key\n",
    "procedure here is estimating $\\alpha_{ij}$. See the lecture notes on how to do\n",
    "that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(\n",
    "    num_layers: int,\n",
    "    num_qubits: int,\n",
    "    thetas: NDArray[np.float64],\n",
    "    A: NDArray[np.float64],\n",
    "    E: NDArray[np.float64],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    num_layers, num_qubits, thetas: used to create the ansatz\n",
    "\n",
    "    A: the square matrix we're trying to perform PCA on\n",
    "\n",
    "    E: the eigenvalues of the global Hamiltonian\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Estimate V(theta) |Ai>\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient\n",
    "\n",
    "Let's implement the gradient of the cost function. This is very easy once we've\n",
    "implemented the cost function. The analytical formula of the gradient is:\n",
    "\n",
    "$$ \\frac{\\partial C(\\theta)}{\\partial \\theta_v} = \\frac{1}{2} (C(\\theta_+) - C(\\theta_-)) $$\n",
    "\n",
    "See the paper (section IV C equation 28) for details. Note that this is a\n",
    "partial derivative w.r.t. *one* parameter $\\theta_v$. Simply calculate the\n",
    "partial derivative for each parameter and concat them into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_gradient(\n",
    "    num_layers: int,\n",
    "    num_qubits: int,\n",
    "    thetas: NDArray[np.float64],\n",
    "    A: NDArray[np.float64],\n",
    "    E: NDArray[np.float64],\n",
    "    v: int,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    v: the index of the parameter (thetas) we're differentiating w.r.t.\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def gradient(\n",
    "    num_layers: int,\n",
    "    num_qubits: int,\n",
    "    thetas: NDArray[np.float64],\n",
    "    A: NDArray[np.float64],\n",
    "    E: NDArray[np.float64],\n",
    ") -> NDArray[np.float64]:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "Let's use PyTorch to implement gradient descent to minimize $C(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    num_layers: int,\n",
    "    num_qubits: int,\n",
    "    thetas: NDArray[np.float64],\n",
    "    A: NDArray[np.float64],\n",
    "    E: NDArray[np.float64],\n",
    "    iters: int,\n",
    "    learning_rate: float = 0.01,\n",
    "    momentum: float = 0.9,\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "    iters: the number of iterations (try 50-300)\n",
    "    learning_rate: gradient descent step size\n",
    "    momentum: momentum parameter for SGD algorithm\n",
    "\n",
    "    Return\n",
    "    ======\n",
    "    Returns the parameters (thetas) that minimize the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    tensor = torch.tensor(thetas, requires_grad=False)\n",
    "    print(tensor.numpy())\n",
    "\n",
    "    optimizer = torch.optim.SGD([tensor], lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    for i in range(iters):\n",
    "        print(f\"Iteration {i}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Calculate the gradient\n",
    "        grad = None\n",
    "\n",
    "        # If this is decreasing, we're heading towards a local min\n",
    "        print(f\"grad magnitude: {np.linalg.norm(grad)}\")\n",
    "\n",
    "        tensor.grad = torch.tensor(grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        print(tensor.numpy())\n",
    "\n",
    "    return tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read $V(\\theta)$\n",
    "\n",
    "Let's implement a function to read the eigenvectors from $V(\\theta)$. The idea\n",
    "is the same as estimating $V(\\theta) |A_i\\rangle$, except we use the standard\n",
    "basis vectors instead of $|A_i\\rangle$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz_to_eigenvectors(\n",
    "    num_layers: int,\n",
    "    num_qubits: int,\n",
    "    thetas: NDArray[np.float64],\n",
    ") -> NDArray[np.float64]:\n",
    "    \"\"\"\n",
    "    Return\n",
    "    ======\n",
    "    Returns a matrix whose rows are the eigenvectors\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
